# ETL итоговое задание
## Задание 1: Работа с Yandex Transfer
1. В консоли управления создана база данных "online_retail".  
[Скрипт создания](./scripts/task_1/create_table.sql)
2. В созданную таблицу загружен [датасет онлайн продаж](https://www.kaggle.com/datasets/mathchi/online-retail-ii-data-set-from-ml-repository).
3. Так как нет возможности импортировать данные с трансформацией в колонку с типом datetime, то колонку с данными даты счета загружал в текстовом виде и затем создал нову колонку с типом datetime, которую уже заполнил по исходным данным.  
[Скрипт заполнения](./scripts/task_1/convert_date.sql)  
1. Созданы эндпойнты приемника и источника  
![alt text](pictures/task1_endpoints.png)  
1. Создан трансфер  
![alt text](pictures/task1_created_transfer.png)
1. После выполнения трансфера в объектном хранилище создался файл перенесенных данных  
![alt text](pictures/task1_end_job.png)
## Задание 2: Автоматизация работы с Yandex Data Processing при помощи Apache AirFlow
1. Создана и настроена вся инфраструктура для Managed Service for Apache Airflow в соответствии с гайдами.
2. Создан кластер Apache Airflow.
3. Создан [DAG скрипт](./scripts/task_2/daily_convert_onlne_sales-DAG.py), который создает новый кластер yandex data processing, запускает задание pyspark и удаляет созданный кластер.
4. Создан [скрипт задания](./scripts/task_2/convert.py), логика которого следующая:  
   - Предполагается, что задание - это регулярная операция. Файлы для обработки в директории источника появляются ежедневно и наименование файла за теущий день содержит в начале имени дату формирования. Даг запускается раз в день и обрабатывает файлы за текущий день.
   - Скрипт запускается, по текущей дате формирует ожидаемое имя файла источника, читает этот файл.
   - Скрипт преобразует типы данных исходного файла. Даты заказов пытается прочитать в разных форматах, так как в исходном датасете у дней, месяцев и часов могут отстуствовть лидирующие нули.
   - Записывает файл в бакет объектного хранилища в формате parquet.
Результат выполнения дага:
![alt text](pictures/task_2_dag_executed.png)
![alt text](pictures/task_2_output_files.png)
## Задание 3: Работа с топиками Apache Kafka® с помощью PySpark-заданий в Yandex Data Processing